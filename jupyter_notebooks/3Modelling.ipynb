{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## The objectives are as follows:\n",
                "\n",
                "\n",
                "- Respond to Business Requirement 2:\n",
                "\n",
                "    - There is a client who wants to know whether a given image of a cherry leaf is healthy or if it has powdery mildew.\n",
                "\n",
                "\n",
                "\n",
                "## Inputs\n",
                "\n",
                "\n",
                "    Following sets:\n",
                "\n",
                "* Train\n",
                "\n",
                "* Validation\n",
                "\n",
                "* Test\n",
                "\n",
                "\n",
                "\n",
                "## Outputs\n",
                "\n",
                "\n",
                "- Images distribution plot in train, validation, and test set.\n",
                "\n",
                "- Increasing data diversity by enhancing images.\n",
                "\n",
                "- Adjusting label predictions during inference by modifying class indices.\n",
                "\n",
                "- Machine learning model creation and training.\n",
                "\n",
                "- The trained model should be preserved (saved).\n",
                "\n",
                "- The learning curve is plotted to visualize the performance of the model.\n",
                "\n",
                "- Evaluating the model's performance.\n",
                "\n",
                "- Making predictions on a randomly selected image file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import os\n",
                "current_dir = os.getcwd()\n",
                "current_dir\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "os.chdir(os.path.dirname(current_dir))\n",
                "print(\"You set a new current directory\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "work_dir = os.getcwd()\n",
                "work_dir"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from matplotlib.image import imread\n",
                "import joblib\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.models import Sequential, load_model\n",
                "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
                "from tensorflow.keras.callbacks import EarlyStopping\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras.preprocessing import image\n",
                "import random\n",
                "import math\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "my_data_dir = 'inputs/datasets/cherry-leaves' \n",
                "my_data_dir = '/workspace/project5/inputs/datasets/cherry-leaves/'\n",
                "\n",
                "train_path = my_data_dir + '/train'\n",
                "validation_path = my_data_dir + '/validation'\n",
                "test_path = my_data_dir + '/test'\n",
                "my_data_dir\n",
                "\n",
                "version = 'v2'\n",
                "file_path = f'outputs/{version}'\n",
                "\n",
                "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
                "  print('There is a version is already available, please create a new version.')\n",
                "  pass\n",
                "else:\n",
                "  os.makedirs(name=file_path)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "labels = os.listdir(train_path)\n",
                "\n",
                "print(f\"The project labels are: {labels}\")\n",
                "\n",
                "version = 'v2'\n",
                "image_shape = joblib.load(filename=f\"outputs/{version}/images_shapes.pkl\")\n",
                "image_shape"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Retrieve the counts of images in the train, validation, and test datasets, and generate a plot displaying the distribution of images across these datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "image_counts = []\n",
                "for folder in ['train', 'validation', 'test']:\n",
                "    counts = [len(os.listdir(f\"{my_data_dir}/{folder}/{label}\")) for label in labels]\n",
                "    image_counts.extend(zip([folder] * len(labels), labels, counts))\n",
                "    print('\\n'.join([f\"* {folder} - {label}: {count} images\" for label, count in zip(labels, counts)]))\n",
                "\n",
                "image_counts_summary = pd.DataFrame(image_counts, columns=['Set', 'Label', 'Frequency'])\n",
                "labels_with_folders = [f\"{folder}: {label}\" for folder, label in zip(image_counts_summary['Set'], image_counts_summary['Label'])]\n",
                "\n",
                "custom_colors = [\"#4287f5\", \"#f54242\", \"#42f56a\", \"#f5ad42\", \"#7a42f5\", \"#42f5e8\"]\n",
                "\n",
                "plt.pie(\n",
                "    image_counts_summary['Frequency'],\n",
                "    labels=labels_with_folders,\n",
                "    autopct='%1.1f%%',\n",
                "    textprops={'color': 'blue'},\n",
                "    pctdistance=0.8,\n",
                "    wedgeprops={'linewidth': 8},\n",
                "    colors=custom_colors \n",
                ")\n",
                "\n",
                "plt.title(\"'Percentage of Each Image Type per Data Set'\")\n",
                "plt.axis('equal')\n",
                "\n",
                "plt.legend(\n",
                "    image_counts_summary['Set'],\n",
                "    title='Data set folder',\n",
                "    loc='upper left',\n",
                "    bbox_to_anchor=(1, 0, 0.5, 1),\n",
                "    handleheight=2\n",
                ")\n",
                "\n",
                "plt.savefig(f'{file_path}/labels_distribution_pie.png', bbox_inches='tight', dpi=150)\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set_style(\"darkgrid\")\n",
                "plt.figure(figsize=(8, 5))\n",
                "\n",
                "custom_palette = [\"#4287f5\", \"#f54242\", \"#42f56a\"] \n",
                "\n",
                "sns.barplot(\n",
                "    data=pd.DataFrame(image_counts, columns=['Set', 'Label', 'Frequency']),\n",
                "    x='Set',\n",
                "    y='Frequency',\n",
                "    hue='Label',\n",
                "    palette=custom_palette  \n",
                ")\n",
                "\n",
                "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
                "plt.show()\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Enhancing the training process, by utilizing the ImageDataGenerator library to employ image data augmentation techniques. This will create a varied set of temporary images within the training dataset, thereby enhancing the training process"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualize Augmented Training Images##"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "training_batch_size = 20\n",
                "\n",
                "augmented_test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
                "    test_path,                                                                            \n",
                "    target_size=image_shape[:2],\n",
                "    color_mode='rgb',\n",
                "    batch_size=training_batch_size,\n",
                "    class_mode='binary',\n",
                "    shuffle=False\n",
                ")\n",
                "\n",
                "\n",
                "augmented_train_set = ImageDataGenerator(\n",
                "    rescale=1./255,\n",
                "    rotation_range=20,\n",
                "    width_shift_range=0.1,\n",
                "    height_shift_range=0.1,\n",
                "    shear_range=0.1,\n",
                "    zoom_range=0.1,\n",
                "    horizontal_flip=True,\n",
                "    vertical_flip=True,\n",
                "    fill_mode='nearest'\n",
                ").flow_from_directory(\n",
                "    train_path,\n",
                "    target_size=image_shape[:2],\n",
                "    color_mode='rgb',\n",
                "    batch_size=training_batch_size,\n",
                "    class_mode='binary',\n",
                "    shuffle=True\n",
                ")\n",
                "\n",
                "\n",
                "augmented_validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
                "    validation_path,\n",
                "    target_size=image_shape[:2],\n",
                "    color_mode='rgb',\n",
                "    batch_size=training_batch_size,\n",
                "    class_mode='binary',\n",
                "    shuffle=False\n",
                ")\n",
                "\n",
                "print(\"Test class Found {0} images belonging to {1} classes.\".format(augmented_test_set.samples, len(augmented_test_set.class_indices)))\n",
                "\n",
                "print(\"Train class Found {0} images belonging to {1} classes.\".format(augmented_train_set.samples, len(augmented_train_set.class_indices)))\n",
                "\n",
                "print(\"Validation class Found {0} images belonging to {1} classes.\".format(augmented_validation_set.samples, len(augmented_validation_set.class_indices)))\n",
                "\n",
                "# #---------------------------------------------\n",
                "\n",
                "\n",
                "# training_batch_size = 20\n",
                "# image_size_reduction = 0.75  # 25% reduction in size\n",
                "\n",
                "# augmented_test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
                "#     test_path,\n",
                "#     target_size=(int(image_shape[0] * image_size_reduction), int(image_shape[1] * image_size_reduction)),\n",
                "#     color_mode='rgb',\n",
                "#     batch_size=training_batch_size,\n",
                "#     class_mode='binary',\n",
                "#     shuffle=False\n",
                "# )\n",
                "\n",
                "# augmented_train_set = ImageDataGenerator(\n",
                "#     rescale=1./255,\n",
                "#     rotation_range=20,\n",
                "#     width_shift_range=0.1,\n",
                "#     height_shift_range=0.1,\n",
                "#     shear_range=0.1,\n",
                "#     zoom_range=0.1,\n",
                "#     horizontal_flip=True,\n",
                "#     vertical_flip=True,\n",
                "#     fill_mode='nearest'\n",
                "# ).flow_from_directory(\n",
                "#     train_path,\n",
                "#     target_size=(int(image_shape[0] * image_size_reduction), int(image_shape[1] * image_size_reduction)),\n",
                "#     color_mode='rgb',\n",
                "#     batch_size=training_batch_size,\n",
                "#     class_mode='binary',\n",
                "#     shuffle=True\n",
                "# )\n",
                "\n",
                "# augmented_validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
                "#     validation_path,\n",
                "#     target_size=(int(image_shape[0] * image_size_reduction), int(image_shape[1] * image_size_reduction)),\n",
                "#     color_mode='rgb',\n",
                "#     batch_size=training_batch_size,\n",
                "#     class_mode='binary',\n",
                "#     shuffle=False\n",
                "# )\n",
                "\n",
                "# print(\"Test class Found {0} images belonging to {1} classes.\".format(augmented_test_set.samples, len(augmented_test_set.class_indices)))\n",
                "# print(\"Train class Found {0} images belonging to {1} classes.\".format(augmented_train_set.samples, len(augmented_train_set.class_indices)))\n",
                "# print(\"Validation class Found {0} images belonging to {1} classes.\".format(augmented_validation_set.samples, len(augmented_validation_set.class_indices)))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "datasets = {\n",
                "    'Augmented Test Image': augmented_test_set,\n",
                "    'Augmented Training Image': augmented_train_set,\n",
                "    'Augmented Validation Image': augmented_validation_set\n",
                "}\n",
                "\n",
                "for dataset_name, dataset in datasets.items():\n",
                "    for _ in range(1):\n",
                "        img, _ = dataset.next()\n",
                "        plt.imshow(img[0])\n",
                "        plt.title(dataset_name)\n",
                "        plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "joblib.dump(value=augmented_train_set.class_indices,\n",
                "            filename=f\"{file_path}/train_classes_indices.pkl\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Creating the model section:"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### - Creating an image classification model using convolutional, pooling, dense, and dropout layers, compiles it, and returns the model. Summary() method is then called to display the model architecture summary."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "def create_image_classification_model():\n",
                "    model = Sequential([\n",
                "        Conv2D(32, (3, 3), input_shape=image_shape, activation='relu'),\n",
                "        MaxPooling2D((2, 2)),\n",
                "        Conv2D(64, (3, 3), activation='relu'),\n",
                "        MaxPooling2D((2, 2)),\n",
                "        Conv2D(64, (3, 3), activation='relu'),\n",
                "        MaxPooling2D((2, 2)),\n",
                "        Flatten(),\n",
                "        Dense(128, activation='relu'),\n",
                "        Dropout(0.5),\n",
                "        Dense(1, activation='sigmoid')\n",
                "    ])\n",
                "\n",
                "    model.compile(loss='binary_crossentropy',\n",
                "                  optimizer='adam',\n",
                "                  metrics=['accuracy'])\n",
                "\n",
                "    return model\n",
                "create_image_classification_model().summary()\n",
                "\n",
                "\n",
                "# ----------------------------\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Training an image classification model using 'augmented_train_set' dataset and validating it using the 'augmented_validation_set' dataset. EarlyStopping callback to stop training if the validation accuracy does not improve for _5_ consecutive epochs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "model = create_image_classification_model()\n",
                "\n",
                "model.fit(augmented_train_set,\n",
                "          epochs=15,\n",
                "          validation_data=augmented_validation_set,\n",
                "          verbose=1)\n",
                "\n",
                "model.save('outputs/v2/model training/cherry_mildew_model.h5')\n",
                "print(f\"Model saved as {model}\")\n",
                "\n",
                "#----------------------------------------------\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Checking the performance of the created model\n",
                "\n",
                "- Generating two plots: one for the loss values and one for the accuracy values from the model training history. Print plots as images."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "losses = pd.DataFrame(model.history.history)\n",
                "\n",
                "sns.set_style(\"darkgrid\")\n",
                "losses[['loss', 'val_loss']].plot(style='.-', color=['#4287f5', '#f54242'])\n",
                "plt.title(\"Loss\")\n",
                "plt.legend(['Training Loss', 'Validation Loss'])  # Change legend labels\n",
                "plt.savefig(f'{file_path}/model_training_losses.png', bbox_inches='tight', dpi=150)\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n\")\n",
                "\n",
                "losses[['accuracy', 'val_accuracy']].plot(style='.-', color=['#42f56a', '#f5ad42'])\n",
                "plt.title(\"Accuracy\")\n",
                "plt.legend(['Training Accuracy', 'Validation Accuracy'])  # Change legend labels\n",
                "plt.savefig(f'{file_path}/model_training_acc.png', bbox_inches='tight', dpi=150)\n",
                "plt.show()\n",
                "## ---------------------------------------------\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Evaluating the created Model \n",
                "\n",
                "- \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "os.makedirs(\"outputs/v2/model training/evaluation\", exist_ok=True)\n",
                "\n",
                "model = load_model('outputs/v2/model training/cherry_mildew_model.h5')\n",
                "loss_accuracy_evaluation = model.evaluate(augmented_test_set)\n",
                "joblib.dump(value=loss_accuracy_evaluation, filename=\"outputs/v2/model training/evaluation/model_evaluation.pkl\")\n",
                "\n",
                "#---------------------------------------------"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " # Prediction on new data\n",
                "- Randomly selecting an image, perfoming classification prediction, and displaying the prediction classification, probability, and image file path to check."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select a random label and image\n",
                "random_label, random_image = random.choice([(label, image) for label in labels for image in os.listdir(test_path + '/' + label)])\n",
                "\n",
                "# Full directory path of the randomly chosen image\n",
                "image_path = os.path.join(test_path, random_label, random_image)\n",
                "\n",
                "# Load and resize the image\n",
                "pil_image = image.load_img(image_path, target_size=image_shape, color_mode='rgb')\n",
                "my_image = np.expand_dims(image.img_to_array(pil_image) / 255.0, axis=0)\n",
                "\n",
                "pred_proba = model.predict(my_image)[0, 0]\n",
                "\n",
                "target_map = {v: k for k, v in augmented_train_set.class_indices.items()}\n",
                "pred_class = target_map[pred_proba > 0.5]\n",
                "if pred_class == target_map[0]:\n",
                "    pred_proba = 1 - pred_proba\n",
                "\n",
                "truncated_proba = math.trunc(pred_proba * 100 * 100) / 100\n",
                "desired_path = '/'.join(image_path.split('/')[4:])\n",
                "\n",
                "print(\"Prediction Classification:\", pred_class)\n",
                "print(\"Probability of Matching Classification: {}%\".format(truncated_proba))\n",
                "print(\"Image File Path check:\", desired_path)\n",
                "pil_image\n",
                "#--------------------------\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip uninstall -y tensorflow keras pyarrow numpy scipy\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "def delete_directory(directory_path):\n",
                "    \"\"\"Deletes the specified directory and all of its contents.\n",
                "\n",
                "    Args:\n",
                "        directory_path (str): The path to the directory to delete.\n",
                "    \"\"\"\n",
                "\n",
                "    if os.path.exists(directory_path):\n",
                "        for file in os.listdir(directory_path):\n",
                "            file_path = os.path.join(directory_path, file)\n",
                "            if os.path.isfile(file_path):\n",
                "                os.remove(file_path)\n",
                "            elif os.path.isdir(file_path):\n",
                "                delete_directory(file_path)\n",
                "        os.rmdir(directory_path)\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    # Get the path to the train and test directories.\n",
                "    train_path = os.path.join(my_data_dir, \"train\")\n",
                "    test_path = os.path.join(my_data_dir, \"test\")\n",
                "\n",
                "    # Delete the train and test directories.\n",
                "    delete_directory(train_path)\n",
                "    delete_directory(test_path)\n",
                "\n",
                "    print(\"Successfully deleted the train and test directories.\")\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Summary"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Objective: Respond to Business Requirement 2 by determining the health status (healthy or powdery mildew) of cherry leaves based on given images.\n",
                "\n",
                "- Analyzed and visualized the distribution of images in the train, validation, and test sets.\n",
                "- Prepared augmented image datasets for training, validation, and testing.\n",
                "- Created a deep learning model for image classification using Convolutional Neural Networks (CNN).\n",
                "- Trained the model on the augmented training set and evaluated its performance on the augmented validation set.\n",
                "- Saved the trained model for future use.\n",
                "- Plotted and analyzed the model's training loss and accuracy.\n",
                "- Evaluated the model's performance on the augmented test set and saved the evaluation results.\n",
                "- Made predictions on a randomly selected image using the trained model and displayed the prediction classification, probability, and image information."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### To Fix:\n",
                "- Code for generating and displaying augmented images from the augmented_train_set is not working\"- Fixed by correcting syntax\n",
                "- loss and val_accuracy don't seem to be good as there is high loss and and low accuracy.\n",
                "    - Tried increasing augmented data from 2 to 10 range to see if that improves accuracy but did not work.\n",
                "        - Fixed by correcting the wrong selected columns. Corrected \"['loss', 'val_accuracy']\" to \"['loss', 'val_loss']\"\n",
                "- Code wont run unless I have requirement.txt file ran at the beginning....\n",
                "- Reduce dataset (Box 10) down from 7 each if possible."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.1"
        },
        "orig_nbformat": 2
    },
    "nbformat": 4,
    "nbformat_minor": 2
}

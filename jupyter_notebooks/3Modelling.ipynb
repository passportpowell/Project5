{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python381264bit3812pyenvc04d3d2ca57d4331bd2ef17489335b1f",
   "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## The objectives are as follows:\n",
    "\n",
    "\n",
    "- Respond to Business Requirement 2:\n",
    "\n",
    "    - There is a client who wants to know whether a given image of a cherry leaf is healthy or if it has powdery mildew.\n",
    "\n",
    "\n",
    "\n",
    "## Inputs\n",
    "\n",
    "\n",
    "    Following sets:\n",
    "\n",
    "* Train\n",
    "\n",
    "* Validation\n",
    "\n",
    "* Test\n",
    "\n",
    "\n",
    "\n",
    "## Outputs\n",
    "\n",
    "\n",
    "- Images distribution plot in train, validation, and test set.\n",
    "\n",
    "- Increasing data diversity by enhancing images.\n",
    "\n",
    "- Adjusting label predictions during inference by modifying class indices.\n",
    "\n",
    "- Machine learning model creation and training.\n",
    "\n",
    "- The trained model should be preserved (saved).\n",
    "\n",
    "- The learning curve is plotted to visualize the performance of the model.\n",
    "\n",
    "- Evaluating the model's performance.\n",
    "\n",
    "- Making predictions on a randomly selected image file."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = os.getcwd()\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread\n",
    "import joblib\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_data_dir = 'inputs/datasets/cherry-leaves'\n",
    "train_path = my_data_dir + '/train'\n",
    "val_path = my_data_dir + '/validation'\n",
    "test_path = my_data_dir + '/test'\n",
    "my_data_dir\n",
    "\n",
    "version = 'v1'\n",
    "file_path = f'outputs/{version}'\n",
    "\n",
    "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
    "  print('There is a version is already available, please create a new version.')\n",
    "  pass\n",
    "else:\n",
    "  os.makedirs(name=file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = os.listdir(train_path)\n",
    "\n",
    "print(f\"The project labels are: {labels}\")\n",
    "\n",
    "version = 'v1'\n",
    "image_shape = joblib.load(filename=f\"outputs/{version}/images_shapes.pkl\")\n",
    "image_shape"
   ]
  },
  {
   "source": [
    "### Retrieve the counts of images in the train, validation, and test datasets, and generate a plot displaying the distribution of images across these datasets."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_counts = []\n",
    "for folder in ['train', 'validation', 'test']:\n",
    "    counts = [len(os.listdir(f\"{my_data_dir}/{folder}/{label}\")) for label in labels]\n",
    "    image_counts.extend(zip([folder]*len(labels), labels, counts))\n",
    "    print('\\n'.join([f\"* {folder} - {label}: {count} images\" for label, count in zip(labels, counts)]))\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=pd.DataFrame(image_counts, columns=['Set', 'Label', 'Frequency']), x='Set', y='Frequency', hue='Label')\n",
    "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "source": [
    "### Enhancing the training process, by utilizing the ImageDataGenerator library to employ image data augmentation techniques. This will create a varied set of temporary images within the training dataset, thereby enhancing the training process"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "image_augmentor = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest',\n",
    ")\n",
    "\n",
    "training_batch_size = 20\n",
    "\n"
   ]
  },
  {
   "source": [
    "### Visualize Augmented Training Images##"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "augmented_train_set = image_augmentor.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=image_shape[:2],\n",
    "    color_mode='rgb',\n",
    "    batch_size=training_batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "augmented_train_set.class_indices\n",
    "\n",
    "\n",
    "augmented_validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=image_shape[:2],\n",
    "    color_mode='rgb',\n",
    "    batch_size=training_batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "augmented_validation_set.class_indices\n",
    "\n",
    "\n",
    "\n",
    "augmented_test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
    "                                                                  target_size=image_shape[:2],\n",
    "                                                                  color_mode='rgb',\n",
    "                                                                  batch_size=training_batch_size,\n",
    "                                                                  class_mode='binary',\n",
    "                                                                  shuffle=False\n",
    "                                                                  )\n",
    "\n",
    "augmented_test_set.class_indices\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    img, label = augmented_train_set.next()\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for _ in range(5):\n",
    "    img, label = augmented_validation_set.next()\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    img, label = augmented_test_set.next()\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=augmented_train_set.class_indices,\n",
    "            filename=f\"{file_path}/train_classes_indices.pkl\")"
   ]
  },
  {
   "source": [
    "# Creating the model section:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### - Creating an image classification model using convolutional, pooling, dense, and dropout layers, compiles it, and returns the model. Summary() method is then called to display the model architecture summary."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_3 (Conv2D)            (None, 62, 62, 32)        896       \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 31, 31, 32)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 29, 29, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 14, 14, 64)        0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 12, 12, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 6, 6, 64)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 2304)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               295040    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 351,489\nTrainable params: 351,489\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "def create_image_classification_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), input_shape=image_shape, activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "create_image_classification_model().summary()\n"
   ]
  },
  {
   "source": [
    "- Training an image classification model using 'augmented_train_set' dataset and validating it using the 'augmented_validation_set' dataset. EarlyStopping callback to stop training if the validation accuracy does not improve for _5 consecutive epochs."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n148/148 [==============================] - 22s 141ms/step - loss: 1.0271 - accuracy: 0.8081 - val_loss: 0.6850 - val_accuracy: 0.5000\nEpoch 2/10\n148/148 [==============================] - 20s 137ms/step - loss: 0.1708 - accuracy: 0.9440 - val_loss: 0.6818 - val_accuracy: 0.5000\nEpoch 3/10\n148/148 [==============================] - 20s 136ms/step - loss: 0.1592 - accuracy: 0.9416 - val_loss: 0.6864 - val_accuracy: 0.5000\nEpoch 4/10\n148/148 [==============================] - 21s 142ms/step - loss: 0.1388 - accuracy: 0.9470 - val_loss: 0.6877 - val_accuracy: 0.5000\nEpoch 5/10\n148/148 [==============================] - 19s 130ms/step - loss: 0.0919 - accuracy: 0.9667 - val_loss: 0.6875 - val_accuracy: 0.5000\nEpoch 6/10\n148/148 [==============================] - 20s 135ms/step - loss: 0.1362 - accuracy: 0.9514 - val_loss: 0.6944 - val_accuracy: 0.5000\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f84299daa90>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "validation_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "model = create_image_classification_model()\n",
    "\n",
    "model.fit(augmented_train_set,\n",
    "          epochs=10,\n",
    "          validation_data=augmented_validation_set,\n",
    "          callbacks=[validation_stop],\n",
    "          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('outputs/v1/cherry_disease_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Summary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### To Fix:\n",
    "- play around with Patience (L53)and epoch (l53)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}
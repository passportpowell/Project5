{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(ADD HERE THE NOTEBOOK NAME)**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Colect the data from Kaggle, unzip, prepare and storage it for further analysis.\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* The Kaggle JSON file authentication token.\n",
        "\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Create Dataset: inputs/datasets/cherry-leaves\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "\n",
        "* The data must be saved after being prepared, removing any files that are not an images, split the data into Train, Validation and Set folders.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy\n",
            "  Using cached numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "Collecting seaborn\n",
            "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
            "Collecting plotly\n",
            "  Using cached plotly-5.14.1-py2.py3-none-any.whl (15.3 MB)\n",
            "Collecting streamlit\n",
            "  Using cached streamlit-1.22.0-py2.py3-none-any.whl (8.9 MB)\n",
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "Collecting tensorflow-cpu\n",
            "  Using cached tensorflow_cpu-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231.8 MB)\n",
            "Collecting keras\n",
            "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "Collecting protobuf\n",
            "  Using cached protobuf-4.23.2-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "Collecting pandas-profiling\n",
            "  Using cached pandas_profiling-3.2.0-py2.py3-none-any.whl (262 kB)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Using cached contourpy-1.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "Collecting cycler>=0.10\n",
            "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Using cached fonttools-4.39.4-py3-none-any.whl (1.0 MB)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Using cached kiwisolver-1.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from matplotlib->-r /workspace/project5/requirements.txt (line 2)) (23.0)\n",
            "Collecting pillow>=6.2.0\n",
            "  Using cached Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "Collecting pyparsing>=2.3.1\n",
            "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from matplotlib->-r /workspace/project5/requirements.txt (line 2)) (2.8.2)\n",
            "Collecting tenacity>=6.2.0\n",
            "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
            "Collecting altair<5,>=3.2.0\n",
            "  Using cached altair-4.2.2-py3-none-any.whl (813 kB)\n",
            "Collecting blinker>=1.0.0\n",
            "  Using cached blinker-1.6.2-py3-none-any.whl (13 kB)\n",
            "Collecting cachetools>=4.0\n",
            "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting click>=7.0\n",
            "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from streamlit->-r /workspace/project5/requirements.txt (line 5)) (6.1.0)\n",
            "Collecting protobuf\n",
            "  Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "Collecting pyarrow>=4.0\n",
            "  Using cached pyarrow-12.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.9 MB)\n",
            "Collecting pympler>=0.9\n",
            "  Using cached Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
            "Requirement already satisfied: requests>=2.4 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from streamlit->-r /workspace/project5/requirements.txt (line 5)) (2.28.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from streamlit->-r /workspace/project5/requirements.txt (line 5)) (13.3.2)\n",
            "Collecting toml\n",
            "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from streamlit->-r /workspace/project5/requirements.txt (line 5)) (4.5.0)\n",
            "Collecting tzlocal>=1.1\n",
            "  Using cached tzlocal-5.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting validators>=0.2\n",
            "  Using cached validators-0.20.0-py3-none-any.whl\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from streamlit->-r /workspace/project5/requirements.txt (line 5)) (3.1.31)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "  Using cached pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from streamlit->-r /workspace/project5/requirements.txt (line 5)) (6.2)\n",
            "Collecting watchdog\n",
            "  Using cached watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "Collecting scipy>=1.3.2\n",
            "  Using cached scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
            "Collecting joblib>=1.1.1\n",
            "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting absl-py>=1.0.0\n",
            "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "Collecting astunparse>=1.6.0\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting google-pasta>=0.1.1\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3\n",
            "  Using cached grpcio-1.54.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "Collecting h5py>=2.9.0\n",
            "  Using cached h5py-3.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "Collecting jax>=0.3.15\n",
            "  Using cached jax-0.4.10-py3-none-any.whl\n",
            "Collecting libclang>=13.0.0\n",
            "  Using cached libclang-16.0.0-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Collecting opt-einsum>=2.3.2\n",
            "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "Requirement already satisfied: setuptools in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from tensorflow-cpu->-r /workspace/project5/requirements.txt (line 7)) (67.6.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from tensorflow-cpu->-r /workspace/project5/requirements.txt (line 7)) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12\n",
            "  Using cached tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
            "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "Collecting termcolor>=1.1.0\n",
            "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
            "Collecting wrapt<1.15,>=1.11.0\n",
            "  Using cached wrapt-1.14.1-cp311-cp311-linux_x86_64.whl\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
            "  Using cached tensorflow_io_gcs_filesystem-0.32.0-cp311-cp311-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "Collecting pytz>=2020.1\n",
            "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "Collecting tzdata>=2022.1\n",
            "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "Collecting joblib>=1.1.1\n",
            "  Using cached joblib-1.1.1-py2.py3-none-any.whl (309 kB)\n",
            "Collecting pydantic>=1.8.1\n",
            "  Downloading pydantic-1.10.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.0.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from pandas-profiling->-r /workspace/project5/requirements.txt (line 11)) (6.0)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from pandas-profiling->-r /workspace/project5/requirements.txt (line 11)) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.1.1 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from pandas-profiling->-r /workspace/project5/requirements.txt (line 11)) (2.1.2)\n",
            "Collecting visions[type_image_path]==0.7.4\n",
            "  Using cached visions-0.7.4-py3-none-any.whl (102 kB)\n",
            "Collecting htmlmin>=0.1.12\n",
            "  Using cached htmlmin-0.1.12-py3-none-any.whl\n",
            "Collecting missingno>=0.4.2\n",
            "  Using cached missingno-0.5.2-py3-none-any.whl (8.7 kB)\n",
            "Collecting phik>=0.11.1\n",
            "  Using cached phik-0.12.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (679 kB)\n",
            "Collecting tangled-up-in-unicode==0.2.0\n",
            "  Using cached tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
            "Collecting tqdm>=4.48.2\n",
            "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "Collecting multimethod>=1.4\n",
            "  Using cached multimethod-1.9.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from visions[type_image_path]==0.7.4->pandas-profiling->-r /workspace/project5/requirements.txt (line 11)) (22.2.0)\n",
            "Collecting networkx>=2.4\n",
            "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "Collecting imagehash\n",
            "  Using cached ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "Collecting entrypoints\n",
            "  Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from altair<5,>=3.2.0->streamlit->-r /workspace/project5/requirements.txt (line 5)) (4.17.3)\n",
            "Collecting toolz\n",
            "  Using cached toolz-0.12.0-py3-none-any.whl (55 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-cpu->-r /workspace/project5/requirements.txt (line 7)) (0.40.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from gitpython!=3.1.19->streamlit->-r /workspace/project5/requirements.txt (line 5)) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from importlib-metadata>=1.4->streamlit->-r /workspace/project5/requirements.txt (line 5)) (3.15.0)\n",
            "Collecting ml-dtypes>=0.1.0\n",
            "  Using cached ml_dtypes-0.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (190 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests>=2.4->streamlit->-r /workspace/project5/requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests>=2.4->streamlit->-r /workspace/project5/requirements.txt (line 5)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests>=2.4->streamlit->-r /workspace/project5/requirements.txt (line 5)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests>=2.4->streamlit->-r /workspace/project5/requirements.txt (line 5)) (2022.12.7)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from rich>=10.11.0->streamlit->-r /workspace/project5/requirements.txt (line 5)) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from rich>=10.11.0->streamlit->-r /workspace/project5/requirements.txt (line 5)) (2.14.0)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.19.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
            "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
            "  Using cached tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
            "Collecting werkzeug>=1.0.1\n",
            "  Using cached Werkzeug-2.3.4-py3-none-any.whl (242 kB)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from validators>=0.2->streamlit->-r /workspace/project5/requirements.txt (line 5)) (5.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit->-r /workspace/project5/requirements.txt (line 5)) (5.0.0)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit->-r /workspace/project5/requirements.txt (line 5)) (0.19.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit->-r /workspace/project5/requirements.txt (line 5)) (0.1.2)\n",
            "Collecting PyWavelets\n",
            "  Using cached PyWavelets-1.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.0 MB)\n",
            "Collecting pyasn1<0.6.0,>=0.4.6\n",
            "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Installing collected packages: pytz, libclang, htmlmin, flatbuffers, wrapt, werkzeug, watchdog, validators, tzlocal, tzdata, tqdm, toolz, toml, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, tenacity, tangled-up-in-unicode, pyparsing, pympler, pydantic, pyasn1, protobuf, pillow, oauthlib, numpy, networkx, multimethod, markdown, kiwisolver, keras, joblib, grpcio, google-pasta, gast, fonttools, entrypoints, cycler, click, cachetools, blinker, astunparse, absl-py, scipy, rsa, requests-oauthlib, PyWavelets, pydeck, pyasn1-modules, pyarrow, plotly, pandas, opt-einsum, ml-dtypes, h5py, contourpy, visions, scikit-learn, matplotlib, jax, imagehash, google-auth, altair, streamlit, seaborn, phik, google-auth-oauthlib, tensorboard, missingno, tensorflow-cpu, pandas-profiling\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.15.0\n",
            "    Uninstalling wrapt-1.15.0:\n",
            "      Successfully uninstalled wrapt-1.15.0\n",
            "Successfully installed PyWavelets-1.4.1 absl-py-1.4.0 altair-4.2.2 astunparse-1.6.3 blinker-1.6.2 cachetools-5.3.1 click-8.1.3 contourpy-1.0.7 cycler-0.11.0 entrypoints-0.4 flatbuffers-23.5.26 fonttools-4.39.4 gast-0.4.0 google-auth-2.19.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.2 h5py-3.8.0 htmlmin-0.1.12 imagehash-4.3.1 jax-0.4.10 joblib-1.1.1 keras-2.12.0 kiwisolver-1.4.4 libclang-16.0.0 markdown-3.4.3 matplotlib-3.7.1 missingno-0.5.2 ml-dtypes-0.1.0 multimethod-1.9.1 networkx-3.1 numpy-1.23.5 oauthlib-3.2.2 opt-einsum-3.3.0 pandas-2.0.2 pandas-profiling-3.2.0 phik-0.12.3 pillow-9.5.0 plotly-5.14.1 protobuf-3.20.3 pyarrow-12.0.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 pydantic-1.10.8 pydeck-0.8.1b0 pympler-1.0.1 pyparsing-3.0.9 pytz-2023.3 requests-oauthlib-1.3.1 rsa-4.9 scikit-learn-1.2.2 scipy-1.10.1 seaborn-0.12.2 streamlit-1.22.0 tangled-up-in-unicode-0.2.0 tenacity-8.2.2 tensorboard-2.12.3 tensorboard-data-server-0.7.0 tensorflow-cpu-2.12.0 tensorflow-estimator-2.12.0 tensorflow-io-gcs-filesystem-0.32.0 termcolor-2.3.0 threadpoolctl-3.1.0 toml-0.10.2 toolz-0.12.0 tqdm-4.65.0 tzdata-2023.3 tzlocal-5.0.1 validators-0.20.0 visions-0.7.4 watchdog-3.0.0 werkzeug-2.3.4 wrapt-1.14.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# %pip install numpy pandas matplotlib seaborn plotly streamlit scikit-learn tensorflow-cpu keras \n",
        "%pip install -r /workspace/project5/requirements.txt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/project5/jupyter_notebooks'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/project5'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 1 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kaggle==1.5.12\n",
            "  Using cached kaggle-1.5.12-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.10 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from kaggle==1.5.12) (1.16.0)\n",
            "Requirement already satisfied: certifi in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from kaggle==1.5.12) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from kaggle==1.5.12) (2.8.2)\n",
            "Requirement already satisfied: requests in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from kaggle==1.5.12) (2.28.2)\n",
            "Requirement already satisfied: tqdm in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from kaggle==1.5.12) (4.65.0)\n",
            "Collecting python-slugify\n",
            "  Using cached python_slugify-8.0.1-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: urllib3 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from kaggle==1.5.12) (1.26.15)\n",
            "Collecting text-unidecode>=1.3\n",
            "  Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests->kaggle==1.5.12) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests->kaggle==1.5.12) (3.4)\n",
            "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
            "Successfully installed kaggle-1.5.12 python-slugify-8.0.1 text-unidecode-1.3\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install kaggle==1.5.12\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading cherry-leaves.zip to inputs/datasets\n",
            " 95%|███████████████████████████████████▉  | 52.0M/55.0M [00:02<00:00, 28.3MB/s]\n",
            "100%|██████████████████████████████████████| 55.0M/55.0M [00:02<00:00, 24.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "KaggleDatasetPath = \"codeinstitute/cherry-leaves\"\n",
        "DestinationFolder = \"inputs/datasets\"   \n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(DestinationFolder + '/cherry-leaves.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(DestinationFolder)\n",
        "\n",
        "os.remove(DestinationFolder + '/cherry-leaves.zip')\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Preparation Stage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section we are going to check for any files that are not images in the zip & split the files, train, validate and test the sets.\n",
        "\n",
        "## Find and remove files that are not images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_non_image_file(my_data_dir):\n",
        "    \"\"\"Removes non-image files from the specified directory\"\"\"\n",
        "    image_extensions = ('.png', '.jpg', '.jpeg')\n",
        "    for folder in os.listdir(my_data_dir):\n",
        "        folder_path = os.path.join(my_data_dir, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            for file in os.listdir(folder_path):\n",
        "                if not file.lower().endswith(image_extensions):\n",
        "                    os.remove(os.path.join(folder_path, file))\n",
        "    print(f\"Removed non-image files from {my_data_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
        "    \"\"\" Split the data into train, validation and test sets \"\"\"\n",
        "\n",
        "    # Check that the sum of all the ratios is 1\n",
        "    if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
        "        print(\"train_set_ratio + validation_set_ratio + test_set_ratio should sum 1.0\")\n",
        "        return\n",
        "\n",
        "    # Get the class labels\n",
        "    labels = os.listdir(my_data_dir)\n",
        "\n",
        "    # Create train, validation and test folders if they don't already exist\n",
        "    for folder in ['train', 'validation', 'test']:\n",
        "        for label in labels:\n",
        "            os.makedirs(name=f\"{my_data_dir}/{folder}/{label}\", exist_ok=True)\n",
        "\n",
        "    # Loop over each label and move files to the appropriate set\n",
        "    for label in labels:\n",
        "        files = os.listdir(f\"{my_data_dir}/{label}\")\n",
        "        random.shuffle(files)\n",
        "\n",
        "        # Calculate the number of files for each set\n",
        "        train_set_files_qty = int(len(files) * train_set_ratio)\n",
        "        validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
        "\n",
        "        for i, file_name in enumerate(files):\n",
        "            if i < train_set_files_qty:\n",
        "                # Move given file to train set\n",
        "                dest_dir = f\"{my_data_dir}/train/{label}\"\n",
        "            elif i < (train_set_files_qty + validation_set_files_qty):\n",
        "                # Move given file to validation set\n",
        "                dest_dir = f\"{my_data_dir}/validation/{label}\"\n",
        "            else:\n",
        "                # Move given file to test set\n",
        "                dest_dir = f\"{my_data_dir}/test/{label}\"\n",
        "            shutil.move(f\"{my_data_dir}/{label}/{file_name}\", f\"{dest_dir}/{file_name}\")\n",
        "\n",
        "        # Remove the original folder\n",
        "        os.rmdir(f\"{my_data_dir}/{label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_train_validation_test_images(my_data_dir = f\"inputs/datasets/cherry-leaves\",\n",
        "                        train_set_ratio = 0.7,\n",
        "                        validation_set_ratio=0.1,\n",
        "                        test_set_ratio=0.2\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* If you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 17] File exists: 'my_folder'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    # create your folder here\n",
        "    os.makedirs(name='my_folder')\n",
        "except Exception as e:\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Work Done:\n",
        "\n",
        "* Download and cleaning of the data have been completed\n",
        "\n",
        "* There are three folders within the directory inputs/datasets/cherry_leaves, namely Train, Validation, and Test. Each of these folders contains two subfolders: one with images of healthy cherry leaves and the other with images of cherry leaves infected with powdery mildew.\n",
        "\n",
        "* In the next notebook I will visualizing the different types of leaves, obtaining their average and variation images, distinguishing the contrast between them, address business requirement number 1.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Issues:\n",
        "\n",
        "* Was getting a 401 - unathorised error when trying to use the kaggle.json file = Fixed by creating a new api key and using that.\n",
        "\n",
        "* \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "to fix:\n",
        "* Remove kaggle.json file"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
